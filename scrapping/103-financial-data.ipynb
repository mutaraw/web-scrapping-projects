{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define functions to extract data (example for one metric)\n",
    "def extract_data_from_page(html_content, metric):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    ranks = [rank.get_text().strip() for rank in soup.find_all('td', class_='rank-td')]\n",
    "\n",
    "    values_and_prices = []\n",
    "    for rank_td in soup.find_all('td', class_='rank-td'):\n",
    "        next_siblings = rank_td.find_next_siblings('td', class_='td-right')\n",
    "        if len(next_siblings) >= 2:\n",
    "            value = next_siblings[0].get_text(strip=True)\n",
    "            price = next_siblings[1].get_text(strip=True)\n",
    "            values_and_prices.append((value, price))\n",
    "\n",
    "    def extract_name_and_code(name_div):\n",
    "        company_name = name_div.find('div', class_='company-name').get_text(strip=True)\n",
    "        company_code = name_div.find('div', class_='company-code').get_text(strip=True)\n",
    "        return company_name, company_code\n",
    "\n",
    "    name_divs = soup.find_all('div', class_='name-div')\n",
    "    names_and_codes = [extract_name_and_code(name_div) for name_div in name_divs]\n",
    "\n",
    "    today_spans = [\n",
    "        f\"-{span.get_text(strip=True)}\" if 'percentage-red' in span.get('class', []) else span.get_text(strip=True)\n",
    "        for span in soup.find('tbody').find_all('span')\n",
    "        if 'percentage-green' in span.get('class', []) or 'percentage-red' in span.get('class', [])\n",
    "    ]\n",
    "\n",
    "    country_spans = soup.find_all('span', class_='responsive-hidden')\n",
    "    countries = [span.get_text(strip=True) for span in country_spans if len(span.get('class', [])) == 1]\n",
    "\n",
    "    current_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    return {\n",
    "        'Rank': ranks,\n",
    "        'Name': [name for name, code in names_and_codes],\n",
    "        'Code': [code for name, code in names_and_codes],\n",
    "        metric: [value for value, price in values_and_prices],\n",
    "        'Price': [price for value, price in values_and_prices],\n",
    "        'Today': today_spans,\n",
    "        'Country': countries,\n",
    "        'Date': [current_date] * len(ranks)\n",
    "    }\n",
    "\n",
    "# Function to scrape data for a specific metric\n",
    "def scrape_metric_data(metric, initial_url, base_url, num_pages):\n",
    "    all_data = []\n",
    "    all_urls = [initial_url]  # Start with the initial URL\n",
    "\n",
    "    for page_number in range(2, num_pages + 1):\n",
    "        all_urls.append(base_url.format(page_number))\n",
    "\n",
    "    for url in all_urls:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            page_data = extract_data_from_page(response.content, metric)\n",
    "            all_data.append(page_data)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from {url}\")\n",
    "\n",
    "    combined_data = {\n",
    "        'Rank': [rank for data in all_data for rank in data['Rank']],\n",
    "        'Company Name': [name for data in all_data for name in data['Name']],\n",
    "        'Company Code': [code for data in all_data for code in data['Code']],\n",
    "        metric: [value for data in all_data for value in data[metric]],\n",
    "        'Price': [price for data in all_data for price in data['Price']],\n",
    "        'Percentage Today': [today for data in all_data for today in data['Today']],\n",
    "        'Company Country': [country for data in all_data for country in data['Country']],\n",
    "        'Date': [date for data in all_data for date in data['Date']]\n",
    "    }\n",
    "\n",
    "    # Check lengths of lists in combined_data\n",
    "    for key, value in combined_data.items():\n",
    "        print(f\"{key}: {len(value)}\")\n",
    "\n",
    "    # Find the minimum length\n",
    "    min_length = min(len(value) for value in combined_data.values())\n",
    "\n",
    "    # Trim lists to the minimum length\n",
    "    for key in combined_data:\n",
    "        combined_data[key] = combined_data[key][:min_length]\n",
    "\n",
    "    return pd.DataFrame(combined_data)\n",
    "\n",
    "# Scrape data for each metric\n",
    "market_cap_df = scrape_metric_data('Market Cap', 'https://companiesmarketcap.com/', 'https://companiesmarketcap.com/page/{}/', 86)\n",
    "earnings_df = scrape_metric_data('Earnings', 'https://companiesmarketcap.com/most-profitable-companies/', 'https://companiesmarketcap.com/most-profitable-companies/page/{}/', 86)\n",
    "revenue_df = scrape_metric_data('Revenue', 'https://companiesmarketcap.com/largest-companies-by-revenue/', 'https://companiesmarketcap.com/largest-companies-by-revenue/page/{}/', 86)\n",
    "employees_df = scrape_metric_data('Employees', 'https://companiesmarketcap.com/largest-companies-by-number-of-employees/', 'https://companiesmarketcap.com/largest-companies-by-number-of-employees/page/{}/', 86)\n",
    "# pe_ratio_df = scrape_metric_data('P/E Ratio', 'https://companiesmarketcap.com/top-companies-by-pe-ratio/', 'https://companiesmarketcap.com/top-companies-by-pe-ratio/page/{}/', 86)\n",
    "dividend_yield_df = scrape_metric_data('Dividend Yield', 'https://companiesmarketcap.com/top-companies-by-dividend-yield/', 'https://companiesmarketcap.com/top-companies-by-dividend-yield/page/{}/', 86)\n",
    "# market_cap_gain_df = scrape_metric_data('Market Cap Gain', 'https://companiesmarketcap.com/top-companies-by-market-cap-gain/', 'https://companiesmarketcap.com/top-companies-by-market-cap-gain/page/{}/', 86)\n",
    "# operating_margin_df = scrape_metric_data('Operating Margin', 'https://companiesmarketcap.com/top-companies-by-operating-margin/', 'https://companiesmarketcap.com/top-companies-by-operating-margin/page/{}/', 86)\n",
    "total_assets_df = scrape_metric_data('Total Assets', 'https://companiesmarketcap.com/top-companies-by-total-assets/', 'https://companiesmarketcap.com/top-companies-by-total-assets/page/{}/', 86)\n",
    "net_assets_df = scrape_metric_data('Net Assets', 'https://companiesmarketcap.com/top-companies-by-net-assets/', 'https://companiesmarketcap.com/top-companies-by-net-assets/page/{}/', 86)\n",
    "liabilities_df = scrape_metric_data('Liabilities', 'https://companiesmarketcap.com/companies-with-the-highest-liabilities/', 'https://companiesmarketcap.com/companies-with-the-highest-liabilities/page/{}/', 86)\n",
    "debt_df = scrape_metric_data('Debt', 'https://companiesmarketcap.com/companies-with-the-highest-debt/', 'https://companiesmarketcap.com/companies-with-the-highest-debt/page/{}/', 86)\n",
    "cash_on_hand_df = scrape_metric_data('Cash on Hand', 'https://companiesmarketcap.com/companies-with-the-highest-cash-on-hand/', 'https://companiesmarketcap.com/companies-with-the-highest-cash-on-hand/page/{}/', 86)\n",
    "\n",
    "# Merge DataFrames\n",
    "merged_df = (market_cap_df\n",
    "             .merge(earnings_df[['Company Name', 'Company Code','Date', 'Earnings']], how='inner', on=['Company Name', 'Company Code', 'Date'])\n",
    "             .merge(revenue_df[['Company Name', 'Company Code','Date', 'Revenue']], how='inner', on=['Company Name', 'Company Code', 'Date'])\n",
    "             .merge(employees_df[['Company Name', 'Company Code','Date', 'Employees']], how='inner', on=['Company Name', 'Company Code', 'Date'])\n",
    "             .merge(dividend_yield_df[['Company Name', 'Company Code','Date', 'Dividend Yield']], how='inner', on=['Company Name', 'Company Code', 'Date'])\n",
    "             .merge(total_assets_df[['Company Name', 'Company Code','Date', 'Total Assets']], how='inner', on=['Company Name', 'Company Code', 'Date'])\n",
    "             .merge(net_assets_df[['Company Name', 'Company Code','Date', 'Net Assets']], how='inner', on=['Company Name', 'Company Code', 'Date'])\n",
    "             .merge(liabilities_df[['Company Name', 'Company Code','Date', 'Liabilities']], how='inner', on=['Company Name', 'Company Code', 'Date'])\n",
    "             .merge(debt_df[['Company Name', 'Company Code','Date', 'Debt']], how='inner', on=['Company Name', 'Company Code', 'Date'])\n",
    "             .merge(cash_on_hand_df[['Company Name', 'Company Code','Date', 'Cash on Hand']], how='inner', on=['Company Name', 'Company Code', 'Date'])\n",
    "             )\n",
    "\n",
    "df = merged_df.copy()\n",
    "\n",
    "# 1. Replace 'N/A' with pd.NA\n",
    "df['Market Cap'] = df['Market Cap'].replace('N/A', pd.NA)\n",
    "\n",
    "# 2. Standardize all values to trillions\n",
    "def convert_to_trillions(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    value = value.replace('$', '').replace(',', '')\n",
    "    if 'T' in value:\n",
    "        return float(value.replace('T', ''))\n",
    "    elif 'B' in value:\n",
    "        return float(value.replace('B', '')) / 1_000\n",
    "    elif 'M' in value:\n",
    "        return float(value.replace('M', '')) / 1_000_000\n",
    "    else:\n",
    "        return float(value) / 1_000_000_000_000\n",
    "\n",
    "df['Market Cap'] = df['Market Cap'].apply(convert_to_trillions)\n",
    "\n",
    "# 3. Rename the column\n",
    "df.rename(columns={'Market Cap': 'Market Cap In ($T)'}, inplace=True)\n",
    "# 1. Replace 'N/A' with pd.NA\n",
    "df['Price'] = df['Price'].replace('N/A', pd.NA)\n",
    "\n",
    "# 2. Convert all price values to numeric\n",
    "def convert_price_to_numeric(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    return float(value.replace('$', '').replace(',', ''))\n",
    "\n",
    "df['Price'] = df['Price'].apply(convert_price_to_numeric)\n",
    "\n",
    "# 3. Rename the column to show its in dollars\n",
    "df.rename(columns={'Price': 'Price ($)'}, inplace=True)\n",
    "\n",
    "# 1. Replace 'N/A' with pd.NA\n",
    "df['Percentage Today'] = df['Percentage Today'].replace('N/A', pd.NA)\n",
    "\n",
    "# 2. Convert percentage values to numeric\n",
    "def convert_percentage(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    if value.startswith('-'):\n",
    "        return -float(value.replace('%', '').replace('-', '').replace(',', ''))\n",
    "    else:\n",
    "        return float(value.replace('%', '').replace(',', ''))\n",
    "\n",
    "df['Percentage Today'] = df['Percentage Today'].apply(convert_percentage)\n",
    "\n",
    "# 3. Rename the column to show it's a percentage\n",
    "df.rename(columns={'Percentage Today': 'Percentage Change (%)'}, inplace=True)\n",
    "\n",
    "# 1. Replace 'N/A' with pd.NA\n",
    "columns_to_clean = ['Earnings', 'Revenue', 'Debt', 'Liabilities', 'Total Assets', 'Net Assets', 'Dividend Yield', 'Cash on Hand', 'Employees']\n",
    "\n",
    "for column in columns_to_clean:\n",
    "    df[column] = df[column].replace('N/A', pd.NA)\n",
    "\n",
    "# 2. Define a function to convert to numeric and standardize units to billions (if applicable), handling negatives\n",
    "def convert_to_numeric(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    value = value.replace('$', '').replace(',', '')\n",
    "    is_negative = value.startswith('-')\n",
    "    value = value.replace('-', '')\n",
    "\n",
    "    try:\n",
    "        if 'T' in value:\n",
    "            numeric_value = float(value.replace('T', '')) * 1_000\n",
    "        elif 'B' in value:\n",
    "            numeric_value = float(value.replace('B', ''))\n",
    "        elif 'M' in value:\n",
    "            numeric_value = float(value.replace('M', '')) / 1_000\n",
    "        elif '%' in value:  # Specific for Dividend Yield\n",
    "            numeric_value = float(value.replace('%', ''))\n",
    "        else:\n",
    "            numeric_value = float(value)\n",
    "\n",
    "        if is_negative:\n",
    "            numeric_value = -numeric_value\n",
    "\n",
    "        return numeric_value\n",
    "    except ValueError:\n",
    "        return pd.NA\n",
    "\n",
    "# 3. Apply conversion function to each column\n",
    "for column in columns_to_clean:\n",
    "    df[column] = df[column].apply(convert_to_numeric)\n",
    "\n",
    "# 4. Rename columns to indicate they are in billions or percentage\n",
    "rename_columns = {\n",
    "    'Earnings': 'Earnings (B)',\n",
    "    'Revenue': 'Revenue (B)',\n",
    "    'Debt': 'Debt (B)',\n",
    "    'Liabilities': 'Liabilities (B)',\n",
    "    'Total Assets': 'Total Assets (B)',\n",
    "    'Net Assets': 'Net Assets (B)',\n",
    "    'Dividend Yield': 'Dividend Yield (%)',\n",
    "    'Cash on Hand': 'Cash on Hand (B)',\n",
    "    'Employees': 'Employees'\n",
    "}\n",
    "\n",
    "df.rename(columns=rename_columns, inplace=True)\n",
    "df"
   ],
   "id": "1dfbec76c40e3016"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "65ffd9ee2036cf08"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
