{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:27:19.653431Z",
     "start_time": "2024-06-18T07:16:08.759348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define functions to extract data\n",
    "def extract_data_from_page(html_content, metric):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    values_and_prices = []\n",
    "    for rank_td in soup.find_all('td', class_='rank-td'):\n",
    "        next_siblings = rank_td.find_next_siblings('td', class_='td-right')\n",
    "        if len(next_siblings) >= 2:\n",
    "            value = next_siblings[0].get_text(strip=True)\n",
    "            price = next_siblings[1].get_text(strip=True)\n",
    "            values_and_prices.append((value, price))\n",
    "\n",
    "    def extract_name_and_code(name_div):\n",
    "        company_name = name_div.find('div', class_='company-name').get_text(strip=True)\n",
    "        company_code = name_div.find('div', class_='company-code').get_text(strip=True)\n",
    "        return company_name, company_code\n",
    "\n",
    "    name_divs = soup.find_all('div', class_='name-div')\n",
    "    names_and_codes = [extract_name_and_code(name_div) for name_div in name_divs]\n",
    "\n",
    "    today_spans = [\n",
    "        f\"-{span.get_text(strip=True)}\" if 'percentage-red' in span.get('class', []) else span.get_text(strip=True)\n",
    "        for span in soup.find('tbody').find_all('span')\n",
    "        if 'percentage-green' in span.get('class', []) or 'percentage-red' in span.get('class', [])\n",
    "    ]\n",
    "\n",
    "    country_spans = soup.find_all('span', class_='responsive-hidden')\n",
    "    countries = [span.get_text(strip=True) for span in country_spans if len(span.get('class', [])) == 1]\n",
    "\n",
    "    current_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    return {\n",
    "        'Name': [name for name, code in names_and_codes],\n",
    "        'Code': [code for name, code in names_and_codes],\n",
    "        metric: [value for value, price in values_and_prices],\n",
    "        'Price': [price for value, price in values_and_prices],\n",
    "        'Today': today_spans,\n",
    "        'Country': countries,\n",
    "        'Date': [current_date] * len(names_and_codes)\n",
    "    }\n",
    "\n",
    "\n",
    "# Function to scrape data for a specific metric\n",
    "def scrape_metric_data(metric, initial_url, base_url, num_pages):\n",
    "    all_data = []\n",
    "    all_urls = [initial_url]  # Start with the initial URL\n",
    "\n",
    "    for page_number in range(2, num_pages + 1):\n",
    "        all_urls.append(base_url.format(page_number))\n",
    "\n",
    "    for url in all_urls:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            page_data = extract_data_from_page(response.content, metric)\n",
    "            all_data.append(page_data)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from {url}\")\n",
    "\n",
    "    combined_data = {\n",
    "        'Company Name': [name for data in all_data for name in data['Name']],\n",
    "        'Company Code': [code for data in all_data for code in data['Code']],\n",
    "        metric: [value for data in all_data for value in data[metric]],\n",
    "        'Price': [price for data in all_data for price in data['Price']],\n",
    "        'Percentage Today': [today for data in all_data for today in data['Today']],\n",
    "        'Company Country': [country for data in all_data for country in data['Country']],\n",
    "        'Date': [date for data in all_data for date in data['Date']]\n",
    "    }\n",
    "\n",
    "    # Check lengths of lists in combined_data\n",
    "    for key, value in combined_data.items():\n",
    "        print(f\"{key}: {len(value)}\")\n",
    "\n",
    "    # Find the minimum length\n",
    "    min_length = min(len(value) for value in combined_data.values())\n",
    "\n",
    "    # Trim lists to the minimum length\n",
    "    for key in combined_data:\n",
    "        combined_data[key] = combined_data[key][:min_length]\n",
    "\n",
    "    return pd.DataFrame(combined_data)\n",
    "\n",
    "\n",
    "# Function to scrape and save data for multiple metrics\n",
    "def scrape_and_save_all_data():\n",
    "    # Scrape data for each metric\n",
    "    market_cap_df = scrape_metric_data('Market Cap', 'https://companiesmarketcap.com/',\n",
    "                                       'https://companiesmarketcap.com/page/{}/', 86)\n",
    "    earnings_df = scrape_metric_data('Earnings', 'https://companiesmarketcap.com/most-profitable-companies/',\n",
    "                                     'https://companiesmarketcap.com/most-profitable-companies/page/{}/', 86)\n",
    "    revenue_df = scrape_metric_data('Revenue', 'https://companiesmarketcap.com/largest-companies-by-revenue/',\n",
    "                                    'https://companiesmarketcap.com/largest-companies-by-revenue/page/{}/', 86)\n",
    "    employees_df = scrape_metric_data('Employees',\n",
    "                                      'https://companiesmarketcap.com/largest-companies-by-number-of-employees/',\n",
    "                                      'https://companiesmarketcap.com/largest-companies-by-number-of-employees/page/{}/',\n",
    "                                      86)\n",
    "    dividend_yield_df = scrape_metric_data('Dividend Yield',\n",
    "                                           'https://companiesmarketcap.com/top-companies-by-dividend-yield/',\n",
    "                                           'https://companiesmarketcap.com/top-companies-by-dividend-yield/page/{}/',\n",
    "                                           86)\n",
    "    total_assets_df = scrape_metric_data('Total Assets',\n",
    "                                         'https://companiesmarketcap.com/top-companies-by-total-assets/',\n",
    "                                         'https://companiesmarketcap.com/top-companies-by-total-assets/page/{}/', 86)\n",
    "    net_assets_df = scrape_metric_data('Net Assets', 'https://companiesmarketcap.com/top-companies-by-net-assets/',\n",
    "                                       'https://companiesmarketcap.com/top-companies-by-net-assets/page/{}/', 86)\n",
    "    liabilities_df = scrape_metric_data('Liabilities',\n",
    "                                        'https://companiesmarketcap.com/companies-with-the-highest-liabilities/',\n",
    "                                        'https://companiesmarketcap.com/companies-with-the-highest-liabilities/page/{}/',\n",
    "                                        86)\n",
    "    debt_df = scrape_metric_data('Debt', 'https://companiesmarketcap.com/companies-with-the-highest-debt/',\n",
    "                                 'https://companiesmarketcap.com/companies-with-the-highest-debt/page/{}/', 86)\n",
    "    cash_on_hand_df = scrape_metric_data('Cash on Hand',\n",
    "                                         'https://companiesmarketcap.com/companies-with-the-highest-cash-on-hand/',\n",
    "                                         'https://companiesmarketcap.com/companies-with-the-highest-cash-on-hand/page/{}/',\n",
    "                                         86)\n",
    "\n",
    "    merged_df = market_cap_df.merge(\n",
    "        earnings_df[['Company Name', 'Company Code', 'Date', 'Earnings']],\n",
    "        how='inner',\n",
    "        on=['Company Name', 'Company Code', 'Date']\n",
    "    )\n",
    "\n",
    "    merged_df = merged_df.merge(\n",
    "        revenue_df[['Company Name', 'Company Code', 'Date', 'Revenue']],\n",
    "        how='inner',\n",
    "        on=['Company Name', 'Company Code', 'Date']\n",
    "    )\n",
    "\n",
    "    merged_df = merged_df.merge(\n",
    "        employees_df[['Company Name', 'Company Code', 'Date', 'Employees']],\n",
    "        how='inner',\n",
    "        on=['Company Name', 'Company Code', 'Date']\n",
    "    )\n",
    "\n",
    "    merged_df = merged_df.merge(\n",
    "        dividend_yield_df[['Company Name', 'Company Code', 'Date', 'Dividend Yield']],\n",
    "        how='inner',\n",
    "        on=['Company Name', 'Company Code', 'Date']\n",
    "    )\n",
    "\n",
    "    merged_df = merged_df.merge(\n",
    "        total_assets_df[['Company Name', 'Company Code', 'Date', 'Total Assets']],\n",
    "        how='inner',\n",
    "        on=['Company Name', 'Company Code', 'Date']\n",
    "    )\n",
    "\n",
    "    merged_df = merged_df.merge(\n",
    "        net_assets_df[['Company Name', 'Company Code', 'Date', 'Net Assets']],\n",
    "        how='inner',\n",
    "        on=['Company Name', 'Company Code', 'Date']\n",
    "    )\n",
    "\n",
    "    merged_df = merged_df.merge(\n",
    "        liabilities_df[['Company Name', 'Company Code', 'Date', 'Liabilities']],\n",
    "        how='inner',\n",
    "        on=['Company Name', 'Company Code', 'Date']\n",
    "    )\n",
    "\n",
    "    merged_df = merged_df.merge(\n",
    "        debt_df[['Company Name', 'Company Code', 'Date', 'Debt']],\n",
    "        how='inner',\n",
    "        on=['Company Name', 'Company Code', 'Date']\n",
    "    )\n",
    "\n",
    "    merged_df = merged_df.merge(\n",
    "        cash_on_hand_df[['Company Name', 'Company Code', 'Date', 'Cash on Hand']],\n",
    "        how='inner',\n",
    "        on=['Company Name', 'Company Code', 'Date']\n",
    "    )\n",
    "\n",
    "    # Append the data to the existing file\n",
    "    original_file_name = 'original_financial_metrics_data.csv'\n",
    "    if not os.path.exists(original_file_name):\n",
    "        merged_df.to_csv(original_file_name, index=False)\n",
    "    else:\n",
    "        existing_df = pd.read_csv(original_file_name)\n",
    "        combined_df = pd.concat([existing_df, merged_df])\n",
    "        combined_df.to_csv(original_file_name, index=False)\n",
    "\n",
    "    # Create a copy for cleaning\n",
    "    df = merged_df.copy()\n",
    "\n",
    "    # Clean the data\n",
    "\n",
    "    # 1. Replace 'N/A' with pd.NA\n",
    "    df['Market Cap'] = df['Market Cap'].replace('N/A', pd.NA)\n",
    "\n",
    "    # 2. Standardize all values to trillions\n",
    "    def convert_to_trillions(value):\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "        value = value.replace('$', '').replace(',', '')\n",
    "        if 'T' in value:\n",
    "            return float(value.replace('T', ''))\n",
    "        elif 'B' in value:\n",
    "            return float(value.replace('B', '')) / 1_000\n",
    "        elif 'M' in value:\n",
    "            return float(value.replace('M', '')) / 1_000_000\n",
    "        else:\n",
    "            return float(value) / 1_000_000_000_000\n",
    "\n",
    "    df['Market Cap'] = df['Market Cap'].apply(convert_to_trillions)\n",
    "\n",
    "    # 3. Rename the column\n",
    "    df.rename(columns={'Market Cap': 'Market Cap In ($T)'}, inplace=True)\n",
    "\n",
    "    # 1. Replace 'N/A' with pd.NA\n",
    "    df['Price'] = df['Price'].replace('N/A', pd.NA)\n",
    "\n",
    "    # 2. Convert all price values to numeric\n",
    "    def convert_price_to_numeric(value):\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "        return float(value.replace('$', '').replace(',', ''))\n",
    "\n",
    "    df['Price'] = df['Price'].apply(convert_price_to_numeric)\n",
    "\n",
    "    # 3. Rename the column to show its in dollars\n",
    "    df.rename(columns={'Price': 'Price ($)'}, inplace=True)\n",
    "\n",
    "    # 1. Replace 'N/A' with pd.NA\n",
    "    df['Percentage Today'] = df['Percentage Today'].replace('N/A', pd.NA)\n",
    "\n",
    "    # 2. Convert percentage values to numeric\n",
    "    def convert_percentage(value):\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "        if value.startswith('-'):\n",
    "            return -float(value.replace('%', '').replace('-', '').replace(',', ''))\n",
    "        else:\n",
    "            return float(value.replace('%', '').replace(',', ''))\n",
    "\n",
    "    df['Percentage Today'] = df['Percentage Today'].apply(convert_percentage)\n",
    "\n",
    "    # 3. Rename the column to show it's a percentage\n",
    "    df.rename(columns={'Percentage Today': 'Percentage Change (%)'}, inplace=True)\n",
    "\n",
    "    # 1. Replace 'N/A' with pd.NA\n",
    "    columns_to_clean = ['Earnings', 'Revenue', 'Debt', 'Liabilities', 'Total Assets', 'Net Assets', 'Dividend Yield',\n",
    "                        'Cash on Hand', 'Employees']\n",
    "\n",
    "    for column in columns_to_clean:\n",
    "        df[column] = df[column].replace('N/A', pd.NA)\n",
    "\n",
    "    # 2. Define a function to convert to numeric and standardize units to billions (if applicable), handling negatives\n",
    "    def convert_to_numeric(value):\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "        value = value.replace('$', '').replace(',', '')\n",
    "        is_negative = value.startswith('-')\n",
    "        value = value.replace('-', '')\n",
    "\n",
    "        try:\n",
    "            if 'T' in value:\n",
    "                numeric_value = float(value.replace('T', '')) * 1_000\n",
    "            elif 'B' in value:\n",
    "                numeric_value = float(value.replace('B', ''))\n",
    "            elif 'M' in value:\n",
    "                numeric_value = float(value.replace('M', '')) / 1_000\n",
    "            elif '%' in value:  # Specific for Dividend Yield\n",
    "                numeric_value = float(value.replace('%', ''))\n",
    "            else:\n",
    "                numeric_value = float(value)\n",
    "\n",
    "            if is_negative:\n",
    "                numeric_value = -numeric_value\n",
    "\n",
    "            return numeric_value\n",
    "        except ValueError:\n",
    "            return pd.NA\n",
    "\n",
    "    # 3. Apply conversion function to each column\n",
    "    for column in columns_to_clean:\n",
    "        df[column] = df[column].apply(convert_to_numeric)\n",
    "\n",
    "    # 4. Rename columns to indicate they are in billions or percentage\n",
    "    rename_columns = {\n",
    "        'Earnings': 'Earnings (B)',\n",
    "        'Revenue': 'Revenue (B)',\n",
    "        'Debt': 'Debt (B)',\n",
    "        'Liabilities': 'Liabilities (B)',\n",
    "        'Total Assets': 'Total Assets (B)',\n",
    "        'Net Assets': 'Net Assets (B)',\n",
    "        'Dividend Yield': 'Dividend Yield (%)',\n",
    "        'Cash on Hand': 'Cash on Hand (B)',\n",
    "        'Employees': 'Employees'\n",
    "    }\n",
    "\n",
    "    df.rename(columns=rename_columns, inplace=True)\n",
    "\n",
    "    # Save the cleaned DataFrame\n",
    "    cleaned_file_name = 'cleaned_data.csv'\n",
    "    if not os.path.isfile(cleaned_file_name):\n",
    "        df.to_csv(cleaned_file_name, index=False)\n",
    "    else:\n",
    "        existing_df = pd.read_csv(cleaned_file_name)\n",
    "        combined_df = pd.concat([existing_df, df])\n",
    "        combined_df.to_csv(cleaned_file_name, index=False)\n",
    "\n",
    "\n",
    "# Run the scraping function\n",
    "scrape_and_save_all_data()"
   ],
   "id": "65ffd9ee2036cf08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name: 8530\n",
      "Company Code: 8530\n",
      "Market Cap: 8530\n",
      "Price: 8530\n",
      "Percentage Today: 8530\n",
      "Company Country: 8530\n",
      "Date: 8530\n",
      "Company Name: 8530\n",
      "Company Code: 8530\n",
      "Earnings: 8530\n",
      "Price: 8530\n",
      "Percentage Today: 8530\n",
      "Company Country: 8530\n",
      "Date: 8530\n",
      "Company Name: 8530\n",
      "Company Code: 8530\n",
      "Revenue: 8530\n",
      "Price: 8530\n",
      "Percentage Today: 8530\n",
      "Company Country: 8530\n",
      "Date: 8530\n",
      "Company Name: 8530\n",
      "Company Code: 8530\n",
      "Employees: 8530\n",
      "Price: 8530\n",
      "Percentage Today: 8530\n",
      "Company Country: 8530\n",
      "Date: 8530\n",
      "Company Name: 8530\n",
      "Company Code: 8530\n",
      "Dividend Yield: 8530\n",
      "Price: 8530\n",
      "Percentage Today: 17058\n",
      "Company Country: 8530\n",
      "Date: 8530\n",
      "Company Name: 8530\n",
      "Company Code: 8530\n",
      "Total Assets: 8530\n",
      "Price: 8530\n",
      "Percentage Today: 8530\n",
      "Company Country: 8530\n",
      "Date: 8530\n",
      "Company Name: 8530\n",
      "Company Code: 8530\n",
      "Net Assets: 8530\n",
      "Price: 8530\n",
      "Percentage Today: 8530\n",
      "Company Country: 8530\n",
      "Date: 8530\n",
      "Company Name: 8530\n",
      "Company Code: 8530\n",
      "Liabilities: 8530\n",
      "Price: 8530\n",
      "Percentage Today: 8530\n",
      "Company Country: 8530\n",
      "Date: 8530\n",
      "Company Name: 8530\n",
      "Company Code: 8530\n",
      "Debt: 8530\n",
      "Price: 8530\n",
      "Percentage Today: 8530\n",
      "Company Country: 8530\n",
      "Date: 8530\n",
      "Company Name: 8530\n",
      "Company Code: 8530\n",
      "Cash on Hand: 8530\n",
      "Price: 8530\n",
      "Percentage Today: 8530\n",
      "Company Country: 8530\n",
      "Date: 8530\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3a48829d3f59185f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
